{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "def preprocess_data(file, scaler=True):\n",
    "\n",
    "    if type(file) == pd.DataFrame:\n",
    "        df = file\n",
    "    else:\n",
    "        df = pd.read_csv(file)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        df.replace('#NAME?', np.nan, inplace=True)\n",
    "        df['swt_d_3_energy_entropy'] = df['swt_d_3_energy_entropy'].astype(float)\n",
    "        df['swt_d_4_energy_entropy'] = df['swt_d_4_energy_entropy'].astype(float)\n",
    "\n",
    "        features = df[['age', 'sex', 'heart_rate_min', 't_wave_multiscale_permutation_entropy_std', 'heart_rate_max', 't_wave_multiscale_permutation_entropy_median',\n",
    "                    'rs_time_std', 'p_wave_corr_coeff_median', 'rri_median', 'heart_rate_mean', 'rri_cluster_ssd_3', 'rri_fisher_info', 'pnn60',\n",
    "                    'swt_d_4_energy_entropy', 'rri_cluster_ssd_2', 'heart_rate_activity', 'diff_rri_min', 't_wave_permutation_entropy_std',\n",
    "                    'p_wave_sample_entropy_std', 'swt_d_3_energy_entropy', 'p_wave_approximate_entropy_median', 'rpeak_approximate_entropy']]\n",
    "\n",
    "        y = df[['270492004', '164889003', '164890007', '713426002', '445118002', '39732003', '164909002', '251146004', '284470004',\n",
    "                        '47665007', '59118001', '427393009', '426177001', '426783006', '427084000', '164934002', '59931005']]\n",
    "\n",
    "        X = features.fillna(features.median()).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "        if scaler:\n",
    "            scaler = MinMaxScaler()\n",
    "            X = scaler.fit_transform(X)\n",
    "\n",
    "        X_df = pd.DataFrame(X, columns=features.columns)\n",
    "\n",
    "        return X_df, y\n",
    "    \n",
    "# Feature path\n",
    "feature_path = 'data/features/'\n",
    "\n",
    "dfs = []\n",
    "for source in os.listdir(feature_path):\n",
    "    if source.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(feature_path, source))\n",
    "        df['source'] = source[:-10]\n",
    "        dfs.append(df)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8587400000000001\n",
      "0.7713400000000001\n",
      "0.9539\n",
      "0.83666\n",
      "0.92546\n",
      "0.7815599999999999\n",
      "0.92792\n",
      "0.8306999999999999\n",
      "0.93392\n",
      "0.8013199999999999\n",
      "5-Fold CV:\n",
      "split_1_1 {'Macro AUC': 0.7698, 'Micro AUC': 0.8585}\n",
      "split_1_2 {'Macro AUC': 0.7776, 'Micro AUC': 0.8649}\n",
      "split_1_3 {'Macro AUC': 0.768, 'Micro AUC': 0.8566}\n",
      "split_1_4 {'Macro AUC': 0.7605, 'Micro AUC': 0.852}\n",
      "split_1_5 {'Macro AUC': 0.7808, 'Micro AUC': 0.8617}\n",
      "split_2_1 {'Macro AUC': 0.8302, 'Micro AUC': 0.9521}\n",
      "split_2_2 {'Macro AUC': 0.836, 'Micro AUC': 0.9522}\n",
      "split_2_3 {'Macro AUC': 0.8313, 'Micro AUC': 0.9439}\n",
      "split_2_4 {'Macro AUC': 0.844, 'Micro AUC': 0.9631}\n",
      "split_2_5 {'Macro AUC': 0.8418, 'Micro AUC': 0.9582}\n",
      "split_3_1 {'Macro AUC': 0.7672, 'Micro AUC': 0.9201}\n",
      "split_3_2 {'Macro AUC': 0.7965, 'Micro AUC': 0.925}\n",
      "split_3_3 {'Macro AUC': 0.8011, 'Micro AUC': 0.93}\n",
      "split_3_4 {'Macro AUC': 0.7562, 'Micro AUC': 0.9274}\n",
      "split_3_5 {'Macro AUC': 0.7868, 'Micro AUC': 0.9248}\n",
      "split_4_1 {'Macro AUC': 0.833, 'Micro AUC': 0.9324}\n",
      "split_4_2 {'Macro AUC': 0.8296, 'Micro AUC': 0.9346}\n",
      "split_4_3 {'Macro AUC': 0.832, 'Micro AUC': 0.9291}\n",
      "split_4_4 {'Macro AUC': 0.8307, 'Micro AUC': 0.9348}\n",
      "split_4_5 {'Macro AUC': 0.8282, 'Micro AUC': 0.9087}\n",
      "split_5_1 {'Macro AUC': 0.8061, 'Micro AUC': 0.9306}\n",
      "split_5_2 {'Macro AUC': 0.7936, 'Micro AUC': 0.9345}\n",
      "split_5_3 {'Macro AUC': 0.7934, 'Micro AUC': 0.938}\n",
      "split_5_4 {'Macro AUC': 0.8067, 'Micro AUC': 0.9281}\n",
      "split_5_5 {'Macro AUC': 0.8068, 'Micro AUC': 0.9384}\n"
     ]
    }
   ],
   "source": [
    "kfold_path = 'data/split_csvs/5FCV'\n",
    "\n",
    "kfold_results = {}\n",
    "for i in range(1,6):\n",
    "    macro_auc_scores = []\n",
    "    micro_auc_scores = []\n",
    "    \n",
    "    # 5-Fold CV with predetermined folds\n",
    "    for j in range(1,6):\n",
    "        train_split = pd.read_csv(os.path.join(kfold_path, f'train_split_{i}_{j}.csv'))\n",
    "        for idx, row in train_split.iterrows():\n",
    "            train_split.loc[idx, 'id'] = row['path'].split('/')[-1].split('_')[0]\n",
    "        \n",
    "        val_split = pd.read_csv(os.path.join(kfold_path, f'val_split_{i}_{j}.csv'))\n",
    "        for idx, row in val_split.iterrows():\n",
    "            val_split.loc[idx, 'id'] = row['path'].split('/')[-1].split('_')[0]\n",
    "        \n",
    "        df_train = df_all[df_all['id'].isin(train_split['id'])]\n",
    "        df_val = df_all[df_all['id'].isin(val_split['id'])]\n",
    "\n",
    "        X_train, y_train = preprocess_data(file=df_train)\n",
    "        X_val, y_val = preprocess_data(file=df_val)\n",
    "\n",
    "        unavailable_diagnoses_train = y_train.sum()[y_train.sum() < 1].index\n",
    "        unavailable_diagnoses_val = y_val.sum()[y_val.sum() < 1].index\n",
    "        unavailable_diagnoses = unavailable_diagnoses_train.union(unavailable_diagnoses_val)\n",
    "\n",
    "        if len(unavailable_diagnoses) > 0:\n",
    "            y_train = y_train.drop(unavailable_diagnoses, axis=1)\n",
    "            y_val = y_val.drop(unavailable_diagnoses, axis=1)\n",
    "\n",
    "        model = LogisticRegression(max_iter=2000)\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict_proba(X_val)\n",
    "        macro_auc_cv = round(roc_auc_score(y_val, y_pred, average='macro'), 4)\n",
    "        macro_auc_scores.append(macro_auc_cv)\n",
    "        micro_auc_cv = round(roc_auc_score(y_val, y_pred, average='micro'), 4)\n",
    "        micro_auc_scores.append(micro_auc_cv)\n",
    "\n",
    "        kfold_results[f'split_{i}_{j}'] = {\n",
    "            'Macro AUC': macro_auc_cv,\n",
    "            'Micro AUC': micro_auc_cv\n",
    "        }\n",
    "\n",
    "    print(np.mean(micro_auc_scores))\n",
    "    print(np.mean(macro_auc_scores))\n",
    "\n",
    "print('5-Fold CV:')\n",
    "for source, score in kfold_results.items():\n",
    "    print(source, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90895\n",
      "0.814875\n",
      "0.8855\n",
      "0.80055\n",
      "0.896475\n",
      "0.8182499999999999\n",
      "0.89445\n",
      "0.8027\n",
      "0.89515\n",
      "0.8196\n",
      "4-Fold CV:\n",
      "split_1_1 {'Macro AUC': 0.8159, 'Micro AUC': 0.9182}\n",
      "split_1_2 {'Macro AUC': 0.8161, 'Micro AUC': 0.9194}\n",
      "split_1_3 {'Macro AUC': 0.8125, 'Micro AUC': 0.8839}\n",
      "split_1_4 {'Macro AUC': 0.815, 'Micro AUC': 0.9143}\n",
      "split_2_1 {'Macro AUC': 0.8017, 'Micro AUC': 0.8323}\n",
      "split_2_2 {'Macro AUC': 0.7995, 'Micro AUC': 0.906}\n",
      "split_2_3 {'Macro AUC': 0.8005, 'Micro AUC': 0.8974}\n",
      "split_2_4 {'Macro AUC': 0.8005, 'Micro AUC': 0.9063}\n",
      "split_3_1 {'Macro AUC': 0.8149, 'Micro AUC': 0.8458}\n",
      "split_3_2 {'Macro AUC': 0.818, 'Micro AUC': 0.9065}\n",
      "split_3_3 {'Macro AUC': 0.8196, 'Micro AUC': 0.9129}\n",
      "split_3_4 {'Macro AUC': 0.8205, 'Micro AUC': 0.9207}\n",
      "split_4_1 {'Macro AUC': 0.8036, 'Micro AUC': 0.9023}\n",
      "split_4_2 {'Macro AUC': 0.8075, 'Micro AUC': 0.9036}\n",
      "split_4_3 {'Macro AUC': 0.8016, 'Micro AUC': 0.9024}\n",
      "split_4_4 {'Macro AUC': 0.7981, 'Micro AUC': 0.8695}\n",
      "split_5_1 {'Macro AUC': 0.8198, 'Micro AUC': 0.9171}\n",
      "split_5_2 {'Macro AUC': 0.8209, 'Micro AUC': 0.8529}\n",
      "split_5_3 {'Macro AUC': 0.8199, 'Micro AUC': 0.8923}\n",
      "split_5_4 {'Macro AUC': 0.8178, 'Micro AUC': 0.9183}\n"
     ]
    }
   ],
   "source": [
    "kfold_path = 'data/split_csvs/4FCV'\n",
    "\n",
    "kfold_results = {}\n",
    "lso_test_results = {}\n",
    "kfold_results = {}\n",
    "for i in range(1,6):\n",
    "    macro_auc_scores = []\n",
    "    micro_auc_scores = []\n",
    "    \n",
    "    # 4-Fold CV with predetermined folds\n",
    "    for j in range(1,5):\n",
    "        \n",
    "        train_split = pd.read_csv(os.path.join(kfold_path, f'train_split_{i}_{j}.csv'))\n",
    "        for idx, row in train_split.iterrows():\n",
    "            train_split.loc[idx, 'id'] = row['path'].split('/')[-1].split('_')[0]\n",
    "        \n",
    "        val_split = pd.read_csv(os.path.join(kfold_path, f'val_split_{i}_{j}.csv'))\n",
    "        for idx, row in val_split.iterrows():\n",
    "            val_split.loc[idx, 'id'] = row['path'].split('/')[-1].split('_')[0]\n",
    "        df_train = df_all[df_all['id'].isin(train_split['id'])]\n",
    "        df_val = df_all[df_all['id'].isin(val_split['id'])]\n",
    "\n",
    "        X_train, y_train = preprocess_data(file=df_train)\n",
    "        X_val, y_val = preprocess_data(file=df_val)\n",
    "\n",
    "        unavailable_diagnoses_train = y_train.sum()[y_train.sum() < 1].index\n",
    "        unavailable_diagnoses_val = y_val.sum()[y_val.sum() < 1].index\n",
    "        unavailable_diagnoses = unavailable_diagnoses_train.union(unavailable_diagnoses_val)\n",
    "\n",
    "        if len(unavailable_diagnoses) > 0:\n",
    "            y_train = y_train.drop(unavailable_diagnoses, axis=1)\n",
    "            y_val = y_val.drop(unavailable_diagnoses, axis=1)\n",
    "        \n",
    "        model = LogisticRegression(max_iter=2000)\n",
    "        model = OneVsRestClassifier(model)\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = model.predict_proba(X_val)\n",
    "        macro_auc_cv = round(roc_auc_score(y_val, y_pred, average='macro'), 4)\n",
    "        macro_auc_scores.append(macro_auc_cv)\n",
    "        micro_auc_cv = round(roc_auc_score(y_val, y_pred, average='micro'), 4)\n",
    "        micro_auc_scores.append(micro_auc_cv)\n",
    "\n",
    "        kfold_results[f'split_{i}_{j}'] = {\n",
    "            'Macro AUC': macro_auc_cv,\n",
    "            'Micro AUC': micro_auc_cv\n",
    "        }\n",
    "\n",
    "    print(np.mean(micro_auc_scores))\n",
    "    print(np.mean(macro_auc_scores))\n",
    "\n",
    "print('4-Fold CV:')\n",
    "for source, score in kfold_results.items():\n",
    "    print(source, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OvO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro AUC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G12EC</th>\n",
       "      <th>SPH</th>\n",
       "      <th>CPSC_CPSC-Extra</th>\n",
       "      <th>ChapmanShaoxing_Ningbo</th>\n",
       "      <th>PTB_PTBXL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G12EC</th>\n",
       "      <td>0.7827</td>\n",
       "      <td>0.7399</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>0.7493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPH</th>\n",
       "      <td>0.8119</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>0.8090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPSC_CPSC-Extra</th>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.7067</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChapmanShaoxing_Ningbo</th>\n",
       "      <td>0.7879</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.7204</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.7952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTB_PTBXL</th>\n",
       "      <td>0.7705</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.7209</td>\n",
       "      <td>0.7712</td>\n",
       "      <td>0.8083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         G12EC     SPH  CPSC_CPSC-Extra  \\\n",
       "G12EC                   0.7827  0.7399           0.7105   \n",
       "SPH                     0.8119  0.8454           0.7603   \n",
       "CPSC_CPSC-Extra         0.7483  0.7067           0.8360   \n",
       "ChapmanShaoxing_Ningbo  0.7879  0.7882           0.7204   \n",
       "PTB_PTBXL               0.7705  0.7738           0.7209   \n",
       "\n",
       "                        ChapmanShaoxing_Ningbo  PTB_PTBXL  \n",
       "G12EC                                   0.7458     0.7493  \n",
       "SPH                                     0.8131     0.8090  \n",
       "CPSC_CPSC-Extra                         0.7456     0.7109  \n",
       "ChapmanShaoxing_Ningbo                  0.8360     0.7952  \n",
       "PTB_PTBXL                               0.7712     0.8083  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Micro AUC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G12EC</th>\n",
       "      <th>SPH</th>\n",
       "      <th>CPSC_CPSC-Extra</th>\n",
       "      <th>ChapmanShaoxing_Ningbo</th>\n",
       "      <th>PTB_PTBXL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G12EC</th>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.7841</td>\n",
       "      <td>0.6402</td>\n",
       "      <td>0.7887</td>\n",
       "      <td>0.7699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPH</th>\n",
       "      <td>0.8465</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.8039</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.9489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPSC_CPSC-Extra</th>\n",
       "      <td>0.8086</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>0.5844</td>\n",
       "      <td>0.7958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChapmanShaoxing_Ningbo</th>\n",
       "      <td>0.8302</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.8046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTB_PTBXL</th>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.7831</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.9421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         G12EC     SPH  CPSC_CPSC-Extra  \\\n",
       "G12EC                   0.8721  0.7841           0.6402   \n",
       "SPH                     0.8465  0.9650           0.8039   \n",
       "CPSC_CPSC-Extra         0.8086  0.7901           0.9366   \n",
       "ChapmanShaoxing_Ningbo  0.8302  0.8540           0.6475   \n",
       "PTB_PTBXL               0.7964  0.8849           0.7831   \n",
       "\n",
       "                        ChapmanShaoxing_Ningbo  PTB_PTBXL  \n",
       "G12EC                                   0.7887     0.7699  \n",
       "SPH                                     0.7012     0.9489  \n",
       "CPSC_CPSC-Extra                         0.5844     0.7958  \n",
       "ChapmanShaoxing_Ningbo                  0.9375     0.8046  \n",
       "PTB_PTBXL                               0.6845     0.9421  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_path = 'data/features'\n",
    "sources = ['G12EC', 'SPH', 'CPSC_CPSC-Extra', 'ChapmanShaoxing_Ningbo', 'PTB_PTBXL']\n",
    "OvO_results = {}\n",
    "\n",
    "for train_source in sources:\n",
    "\n",
    "    X_train, y_train = preprocess_data(file=os.path.join(feature_path, f'{train_source}_feats.csv'))\n",
    "\n",
    "    unavailable_diagnoses_train = y_train.sum()[y_train.sum() < 1].index\n",
    "    y_train = y_train.drop(unavailable_diagnoses_train, axis=1)\n",
    "\n",
    "    model = LogisticRegression(max_iter=2000, C=1)\n",
    "    model = OneVsRestClassifier(model)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # One source vs one source\n",
    "    OvO_results[train_source] = {}    \n",
    "    for test_source in sources:\n",
    "        X_test, y_test = preprocess_data(file=os.path.join(feature_path, f'{test_source}_feats.csv'))\n",
    "\n",
    "        y_test = y_test.drop(unavailable_diagnoses_train, axis=1)\n",
    "        available_test = (y_test.sum() >= 1)\n",
    "        unavailable_diagnoses_test = y_test.sum()[y_test.sum() < 1].index\n",
    "        y_test = y_test.drop(unavailable_diagnoses_test, axis=1)\n",
    "\n",
    "        y_pred = model.predict_proba(X_test)[:,available_test]\n",
    "\n",
    "        score = {'Macro AUC': round(roc_auc_score(y_test, y_pred, average='macro'), 4),\n",
    "                 'Micro AUC': round(roc_auc_score(y_test, y_pred, average='micro'), 4)\n",
    "        }\n",
    "        \n",
    "        OvO_results[train_source][test_source] = score\n",
    "        \n",
    "avg_macro = 0\n",
    "avg_micro = 0\n",
    "for k in OvO_results.keys():\n",
    "    for k2 in OvO_results[k].keys():\n",
    "        if k != k2:\n",
    "            avg_macro += OvO_results[k][k2]['Macro AUC']\n",
    "            avg_micro += OvO_results[k][k2]['Micro AUC']\n",
    "avg_macro /= len(OvO_results.keys())*(len(OvO_results[k].keys()) - 1)\n",
    "avg_micro /= len(OvO_results.keys())*(len(OvO_results[k].keys()) - 1)\n",
    "\n",
    "df_macro = pd.DataFrame()\n",
    "df_micro = pd.DataFrame()\n",
    "\n",
    "for outer_key, inner_dict in OvO_results.items():\n",
    "    for inner_key, metrics in inner_dict.items():\n",
    "        df_macro.loc[inner_key, outer_key] = metrics.get('Macro AUC', None)\n",
    "        df_micro.loc[inner_key, outer_key] = metrics.get('Micro AUC', None)\n",
    "\n",
    "print(\"Macro AUC:\")\n",
    "display(df_macro)\n",
    "\n",
    "print(\"\\nMicro AUC:\")\n",
    "display(df_micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set G12EC:\n",
      "{'Macro AUC': 0.7261, 'Micro AUC': 0.5831}\n",
      "Test set SPH:\n",
      "{'Macro AUC': 0.7956, 'Micro AUC': 0.843}\n",
      "Test set CPSC_CPSC-Extra:\n",
      "{'Macro AUC': 0.735, 'Micro AUC': 0.7036}\n",
      "Test set ChapmanShaoxing_Ningbo:\n",
      "{'Macro AUC': 0.7966, 'Micro AUC': 0.7288}\n",
      "Test set PTB_PTBXL:\n",
      "{'Macro AUC': 0.7687, 'Micro AUC': 0.7221}\n",
      "\n",
      "Test Macro/Micro: 0.76 / 0.72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'G12EC': {'Macro AUC': 0.7261, 'Micro AUC': 0.5831},\n",
       " 'SPH': {'Macro AUC': 0.7956, 'Micro AUC': 0.843},\n",
       " 'CPSC_CPSC-Extra': {'Macro AUC': 0.735, 'Micro AUC': 0.7036},\n",
       " 'ChapmanShaoxing_Ningbo': {'Macro AUC': 0.7966, 'Micro AUC': 0.7288},\n",
       " 'PTB_PTBXL': {'Macro AUC': 0.7687, 'Micro AUC': 0.7221}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_path = 'data/features'\n",
    "sources = ['G12EC', 'SPH', 'CPSC_CPSC-Extra', 'ChapmanShaoxing_Ningbo', 'PTB_PTBXL']\n",
    "\n",
    "kfold_results = {}\n",
    "lso_train_results = {}\n",
    "lso_test_results = {}\n",
    "for test_source in sources:\n",
    "    lso_train_results[test_source] = {}\n",
    "    train_sources = [s for s in sources if s != test_source]\n",
    "\n",
    "    # LSO test\n",
    "    X_train, y_train = preprocess_data(df_all[~df_all['source'].isin([test_source])])\n",
    "    X_test, y_test = preprocess_data(file=os.path.join(feature_path, f'{test_source}_feats.csv'))\n",
    "\n",
    "    unavailable_diagnoses_train = y_train.sum()[y_test.sum() < 1].index\n",
    "    unavailable_diagnoses_test = y_test.sum()[y_test.sum() < 1].index\n",
    "    unavailable_diagnoses = unavailable_diagnoses_train.union(unavailable_diagnoses_test)\n",
    "\n",
    "    if len(unavailable_diagnoses) > 0:\n",
    "        # print(unavailable_diagnoses)\n",
    "        y_test = y_test.drop(unavailable_diagnoses, axis=1)\n",
    "        y_train = y_train.drop(unavailable_diagnoses, axis=1)\n",
    "\n",
    "    model = LogisticRegression(max_iter=2000)\n",
    "    model = OneVsRestClassifier(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)\n",
    " \n",
    "    score = {\n",
    "        'Macro AUC': round(roc_auc_score(y_test, y_pred, average='macro'), 4),\n",
    "        'Micro AUC': round(roc_auc_score(y_test, y_pred, average='micro'), 4)\n",
    "    }\n",
    "    lso_test_results[test_source] = score\n",
    "\n",
    "    print(f'Test set {test_source}:\\n{score}')\n",
    "\n",
    "avg_macro = 0\n",
    "avg_micro = 0\n",
    "for k in lso_test_results.keys():\n",
    "    avg_macro += lso_test_results[k]['Macro AUC']\n",
    "    avg_micro += lso_test_results[k]['Micro AUC']\n",
    "avg_macro /= len(sources)\n",
    "avg_micro /= len(sources)\n",
    "\n",
    "print(f'\\nTest Macro/Micro: {avg_macro:.2f} / {avg_micro:.2f}')\n",
    "\n",
    "lso_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8786000000000002\n",
      "0.7659\n",
      "0.8786000000000002\n",
      "0.7659\n",
      "0.8786000000000002\n",
      "0.7659\n",
      "0.8786000000000002\n",
      "0.7659\n",
      "0.8786000000000002\n",
      "0.7659\n",
      "5-Fold CV:\n",
      "split_1_1 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_1_2 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_1_3 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_1_4 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_1_5 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_2_1 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_2_2 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_2_3 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_2_4 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_2_5 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_3_1 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_3_2 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_3_3 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_3_4 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_3_5 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_4_1 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_4_2 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_4_3 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_4_4 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_4_5 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_5_1 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_5_2 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_5_3 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_5_4 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n",
      "split_5_5 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n"
     ]
    }
   ],
   "source": [
    "kfold_path = 'data/split_csvs/5FCV'\n",
    "kfold_results = {}\n",
    "for i in range(1,6):\n",
    "    macro_auc_scores = []\n",
    "    micro_auc_scores = []\n",
    "    \n",
    "    # 5-Fold CV with predetermined folds\n",
    "    for j in range(1,6):\n",
    "        train_split = pd.read_csv(os.path.join(kfold_path, f'train_split_{i}_{j}.csv'))\n",
    "        for idx, row in train_split.iterrows():\n",
    "            train_split.loc[idx, 'id'] = row['path'].split('/')[-1].split('_')[0]\n",
    "        \n",
    "        val_split = pd.read_csv(os.path.join(kfold_path, f'val_split_{i}_{j}.csv'))\n",
    "        for idx, row in val_split.iterrows():\n",
    "            val_split.loc[idx, 'id'] = row['path'].split('/')[-1].split('_')[0]\n",
    "\n",
    "        X_train, y_train = preprocess_data(file=df_train)\n",
    "        X_val, y_val = preprocess_data(file=df_val)\n",
    "\n",
    "        unavailable_diagnoses_train = y_train.sum()[y_train.sum() < 1].index\n",
    "        unavailable_diagnoses_val = y_val.sum()[y_val.sum() < 1].index\n",
    "        unavailable_diagnoses = unavailable_diagnoses_train.union(unavailable_diagnoses_val)\n",
    "\n",
    "        if len(unavailable_diagnoses) > 0:\n",
    "            y_train = y_train.drop(unavailable_diagnoses, axis=1)\n",
    "            y_val = y_val.drop(unavailable_diagnoses, axis=1)\n",
    "\n",
    "        model = xgb.XGBClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict_proba(X_val)\n",
    "        macro_auc_cv = round(roc_auc_score(y_val, y_pred, average='macro'), 4)\n",
    "        macro_auc_scores.append(macro_auc_cv)\n",
    "        micro_auc_cv = round(roc_auc_score(y_val, y_pred, average='micro'), 4)\n",
    "        micro_auc_scores.append(micro_auc_cv)\n",
    "\n",
    "        kfold_results[f'split_{i}_{j}'] = {\n",
    "            'Macro AUC': macro_auc_cv,\n",
    "            'Micro AUC': micro_auc_cv\n",
    "        }\n",
    "\n",
    "    print(np.mean(micro_auc_scores))\n",
    "    print(np.mean(macro_auc_scores))\n",
    "\n",
    "print('5-Fold CV:')\n",
    "for source, score in kfold_results.items():\n",
    "    print(source, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9208500000000001\n",
      "0.8266\n",
      "0.8728750000000001\n",
      "0.7641249999999999\n",
      "0.86755\n",
      "0.7618\n",
      "0.81605\n",
      "0.7530000000000001\n",
      "0.882925\n",
      "0.7785\n",
      "4-Fold CV:\n",
      "split_1_1 {'Macro AUC': 0.8179, 'Micro AUC': 0.9249}\n",
      "split_1_2 {'Macro AUC': 0.8309, 'Micro AUC': 0.9336}\n",
      "split_1_3 {'Macro AUC': 0.8331, 'Micro AUC': 0.9295}\n",
      "split_1_4 {'Macro AUC': 0.8245, 'Micro AUC': 0.8954}\n",
      "split_2_1 {'Macro AUC': 0.7621, 'Micro AUC': 0.8677}\n",
      "split_2_2 {'Macro AUC': 0.753, 'Micro AUC': 0.8811}\n",
      "split_2_3 {'Macro AUC': 0.7686, 'Micro AUC': 0.8558}\n",
      "split_2_4 {'Macro AUC': 0.7728, 'Micro AUC': 0.8869}\n",
      "split_3_1 {'Macro AUC': 0.7763, 'Micro AUC': 0.8889}\n",
      "split_3_2 {'Macro AUC': 0.7504, 'Micro AUC': 0.8433}\n",
      "split_3_3 {'Macro AUC': 0.7347, 'Micro AUC': 0.8428}\n",
      "split_3_4 {'Macro AUC': 0.7858, 'Micro AUC': 0.8952}\n",
      "split_4_1 {'Macro AUC': 0.7503, 'Micro AUC': 0.8069}\n",
      "split_4_2 {'Macro AUC': 0.7531, 'Micro AUC': 0.7961}\n",
      "split_4_3 {'Macro AUC': 0.7377, 'Micro AUC': 0.8009}\n",
      "split_4_4 {'Macro AUC': 0.7709, 'Micro AUC': 0.8603}\n",
      "split_5_1 {'Macro AUC': 0.7864, 'Micro AUC': 0.8862}\n",
      "split_5_2 {'Macro AUC': 0.7811, 'Micro AUC': 0.8793}\n",
      "split_5_3 {'Macro AUC': 0.7806, 'Micro AUC': 0.8876}\n",
      "split_5_4 {'Macro AUC': 0.7659, 'Micro AUC': 0.8786}\n"
     ]
    }
   ],
   "source": [
    "kfold_path = 'data/split_csvs/4FCV'\n",
    "kfold_results = {}\n",
    "for i in range(1,6):\n",
    "    macro_auc_scores = []\n",
    "    micro_auc_scores = []\n",
    "    \n",
    "    # 4-Fold CV with predetermined folds\n",
    "    for j in range(1,5):\n",
    "        \n",
    "        train_split = pd.read_csv(os.path.join(kfold_path, f'train_split_{i}_{j}.csv'))\n",
    "        for idx, row in train_split.iterrows():\n",
    "            train_split.loc[idx, 'id'] = row['path'].split('/')[-1].split('_')[0]\n",
    "        \n",
    "        val_split = pd.read_csv(os.path.join(kfold_path, f'val_split_{i}_{j}.csv'))\n",
    "        for idx, row in val_split.iterrows():\n",
    "            val_split.loc[idx, 'id'] = row['path'].split('/')[-1].split('_')[0]\n",
    "        df_train = df_all[df_all['id'].isin(train_split['id'])]\n",
    "        df_val = df_all[df_all['id'].isin(val_split['id'])]\n",
    "\n",
    "        X_train, y_train = preprocess_data(file=df_train)\n",
    "        X_val, y_val = preprocess_data(file=df_val)\n",
    "\n",
    "        unavailable_diagnoses_train = y_train.sum()[y_train.sum() < 1].index\n",
    "        unavailable_diagnoses_val = y_val.sum()[y_val.sum() < 1].index\n",
    "        unavailable_diagnoses = unavailable_diagnoses_train.union(unavailable_diagnoses_val)\n",
    "\n",
    "        if len(unavailable_diagnoses) > 0:\n",
    "            y_train = y_train.drop(unavailable_diagnoses, axis=1)\n",
    "            y_val = y_val.drop(unavailable_diagnoses, axis=1)\n",
    "        \n",
    "        model = xgb.XGBClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        y_pred = model.predict_proba(X_val)\n",
    "        macro_auc_cv = round(roc_auc_score(y_val, y_pred, average='macro'), 4)\n",
    "        macro_auc_scores.append(macro_auc_cv)\n",
    "        micro_auc_cv = round(roc_auc_score(y_val, y_pred, average='micro'), 4)\n",
    "        micro_auc_scores.append(micro_auc_cv)\n",
    "\n",
    "        kfold_results[f'split_{i}_{j}'] = {\n",
    "            'Macro AUC': macro_auc_cv,\n",
    "            'Micro AUC': micro_auc_cv\n",
    "        }\n",
    "\n",
    "    print(np.mean(micro_auc_scores))\n",
    "    print(np.mean(macro_auc_scores))\n",
    "\n",
    "print('4-Fold CV:')\n",
    "for source, score in kfold_results.items():\n",
    "    print(source, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OvO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro AUC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G12EC</th>\n",
       "      <th>SPH</th>\n",
       "      <th>CPSC_CPSC-Extra</th>\n",
       "      <th>ChapmanShaoxing_Ningbo</th>\n",
       "      <th>PTB_PTBXL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G12EC</th>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.7193</td>\n",
       "      <td>0.6826</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.6815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPH</th>\n",
       "      <td>0.7316</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.7398</td>\n",
       "      <td>0.7672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPSC_CPSC-Extra</th>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>0.7215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChapmanShaoxing_Ningbo</th>\n",
       "      <td>0.7557</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>0.7264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTB_PTBXL</th>\n",
       "      <td>0.6737</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>0.7142</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>0.9971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         G12EC     SPH  CPSC_CPSC-Extra  \\\n",
       "G12EC                   0.9997  0.7193           0.6826   \n",
       "SPH                     0.7316  0.9992           0.7397   \n",
       "CPSC_CPSC-Extra         0.6915  0.7358           0.9998   \n",
       "ChapmanShaoxing_Ningbo  0.7557  0.7287           0.6985   \n",
       "PTB_PTBXL               0.6737  0.7325           0.7142   \n",
       "\n",
       "                        ChapmanShaoxing_Ningbo  PTB_PTBXL  \n",
       "G12EC                                   0.7464     0.6815  \n",
       "SPH                                     0.7398     0.7672  \n",
       "CPSC_CPSC-Extra                         0.7104     0.7215  \n",
       "ChapmanShaoxing_Ningbo                  0.9918     0.7264  \n",
       "PTB_PTBXL                               0.7085     0.9971  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Micro AUC:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G12EC</th>\n",
       "      <th>SPH</th>\n",
       "      <th>CPSC_CPSC-Extra</th>\n",
       "      <th>ChapmanShaoxing_Ningbo</th>\n",
       "      <th>PTB_PTBXL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G12EC</th>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.6372</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.7495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPH</th>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.7993</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>0.9415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPSC_CPSC-Extra</th>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.7932</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.6430</td>\n",
       "      <td>0.8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChapmanShaoxing_Ningbo</th>\n",
       "      <td>0.7811</td>\n",
       "      <td>0.8439</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.7870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTB_PTBXL</th>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.8492</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.7747</td>\n",
       "      <td>0.9988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         G12EC     SPH  CPSC_CPSC-Extra  \\\n",
       "G12EC                   0.9999  0.7860           0.6372   \n",
       "SPH                     0.8203  0.9996           0.7993   \n",
       "CPSC_CPSC-Extra         0.7448  0.7932           0.9999   \n",
       "ChapmanShaoxing_Ningbo  0.7811  0.8439           0.6764   \n",
       "PTB_PTBXL               0.7090  0.8492           0.7675   \n",
       "\n",
       "                        ChapmanShaoxing_Ningbo  PTB_PTBXL  \n",
       "G12EC                                   0.8313     0.7495  \n",
       "SPH                                     0.8831     0.9415  \n",
       "CPSC_CPSC-Extra                         0.6430     0.8096  \n",
       "ChapmanShaoxing_Ningbo                  0.9972     0.7870  \n",
       "PTB_PTBXL                               0.7747     0.9988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_path = 'data/features'\n",
    "sources = ['G12EC', 'SPH', 'CPSC_CPSC-Extra', 'ChapmanShaoxing_Ningbo', 'PTB_PTBXL']\n",
    "OvO_results = {}\n",
    "\n",
    "for train_source in sources:\n",
    "\n",
    "    X_train, y_train = preprocess_data(file=os.path.join(feature_path, f'{train_source}_feats.csv'))\n",
    "\n",
    "    unavailable_diagnoses_train = y_train.sum()[y_train.sum() < 1].index\n",
    "    y_train = y_train.drop(unavailable_diagnoses_train, axis=1)\n",
    "\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # One source vs one source\n",
    "    OvO_results[train_source] = {}    \n",
    "    for test_source in sources:\n",
    "        X_test, y_test = preprocess_data(file=os.path.join(feature_path, f'{test_source}_feats.csv'))\n",
    "\n",
    "        y_test = y_test.drop(unavailable_diagnoses_train, axis=1)\n",
    "        available_test = (y_test.sum() >= 1)\n",
    "        unavailable_diagnoses_test = y_test.sum()[y_test.sum() < 1].index\n",
    "        y_test = y_test.drop(unavailable_diagnoses_test, axis=1)\n",
    "\n",
    "        y_pred = model.predict_proba(X_test)[:,available_test]\n",
    "\n",
    "        score = {'Macro AUC': round(roc_auc_score(y_test, y_pred, average='macro'), 4),\n",
    "                 'Micro AUC': round(roc_auc_score(y_test, y_pred, average='micro'), 4)\n",
    "        }\n",
    "        \n",
    "        OvO_results[train_source][test_source] = score\n",
    "        \n",
    "avg_macro = 0\n",
    "avg_micro = 0\n",
    "for k in OvO_results.keys():\n",
    "    for k2 in OvO_results[k].keys():\n",
    "        if k != k2:\n",
    "            avg_macro += OvO_results[k][k2]['Macro AUC']\n",
    "            avg_micro += OvO_results[k][k2]['Micro AUC']\n",
    "avg_macro /= len(OvO_results.keys())*(len(OvO_results[k].keys()) - 1)\n",
    "avg_micro /= len(OvO_results.keys())*(len(OvO_results[k].keys()) - 1)\n",
    "\n",
    "df_macro = pd.DataFrame()\n",
    "df_micro = pd.DataFrame()\n",
    "\n",
    "for outer_key, inner_dict in OvO_results.items():\n",
    "    for inner_key, metrics in inner_dict.items():\n",
    "        df_macro.loc[inner_key, outer_key] = metrics.get('Macro AUC', None)\n",
    "        df_micro.loc[inner_key, outer_key] = metrics.get('Micro AUC', None)\n",
    "\n",
    "print(\"Macro AUC:\")\n",
    "display(df_macro)\n",
    "\n",
    "print(\"\\nMicro AUC:\")\n",
    "display(df_micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set G12EC:\n",
      "{'Macro AUC': 0.681, 'Micro AUC': 0.7181}\n",
      "Test set SPH:\n",
      "{'Macro AUC': 0.7074, 'Micro AUC': 0.878}\n",
      "Test set CPSC_CPSC-Extra:\n",
      "{'Macro AUC': 0.6818, 'Micro AUC': 0.7448}\n",
      "Test set ChapmanShaoxing_Ningbo:\n",
      "{'Macro AUC': 0.7192, 'Micro AUC': 0.7865}\n",
      "Test set PTB_PTBXL:\n",
      "{'Macro AUC': 0.7061, 'Micro AUC': 0.7758}\n",
      "\n",
      "Test Macro/Micro: 0.70 / 0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'G12EC': {'Macro AUC': 0.681, 'Micro AUC': 0.7181},\n",
       " 'SPH': {'Macro AUC': 0.7074, 'Micro AUC': 0.878},\n",
       " 'CPSC_CPSC-Extra': {'Macro AUC': 0.6818, 'Micro AUC': 0.7448},\n",
       " 'ChapmanShaoxing_Ningbo': {'Macro AUC': 0.7192, 'Micro AUC': 0.7865},\n",
       " 'PTB_PTBXL': {'Macro AUC': 0.7061, 'Micro AUC': 0.7758}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_path = 'data/features'\n",
    "sources = ['G12EC', 'SPH', 'CPSC_CPSC-Extra', 'ChapmanShaoxing_Ningbo', 'PTB_PTBXL']\n",
    "\n",
    "kfold_results = {}\n",
    "lso_train_results = {}\n",
    "lso_test_results = {}\n",
    "for test_source in sources:\n",
    "    lso_train_results[test_source] = {}\n",
    "    train_sources = [s for s in sources if s != test_source]\n",
    "\n",
    "    # LSO test\n",
    "    X_train, y_train = preprocess_data(df_all[~df_all['source'].isin([test_source])])\n",
    "    X_test, y_test = preprocess_data(file=os.path.join(feature_path, f'{test_source}_feats.csv'))\n",
    "\n",
    "    unavailable_diagnoses_train = y_train.sum()[y_test.sum() < 1].index\n",
    "    unavailable_diagnoses_test = y_test.sum()[y_test.sum() < 1].index\n",
    "    unavailable_diagnoses = unavailable_diagnoses_train.union(unavailable_diagnoses_test)\n",
    "\n",
    "    if len(unavailable_diagnoses) > 0:\n",
    "        # print(unavailable_diagnoses)\n",
    "        y_test = y_test.drop(unavailable_diagnoses, axis=1)\n",
    "        y_train = y_train.drop(unavailable_diagnoses, axis=1)\n",
    "\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)\n",
    " \n",
    "    score = {\n",
    "        'Macro AUC': round(roc_auc_score(y_test, y_pred, average='macro'), 4),\n",
    "        'Micro AUC': round(roc_auc_score(y_test, y_pred, average='micro'), 4)\n",
    "    }\n",
    "    lso_test_results[test_source] = score\n",
    "\n",
    "    print(f'Test set {test_source}:\\n{score}')\n",
    "\n",
    "avg_macro = 0\n",
    "avg_micro = 0\n",
    "for k in lso_test_results.keys():\n",
    "    avg_macro += lso_test_results[k]['Macro AUC']\n",
    "    avg_micro += lso_test_results[k]['Micro AUC']\n",
    "avg_macro /= len(sources)\n",
    "avg_micro /= len(sources)\n",
    "\n",
    "print(f'\\nTest Macro/Micro: {avg_macro:.2f} / {avg_micro:.2f}')\n",
    "\n",
    "lso_test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physionet_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
